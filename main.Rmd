---
title: "Calibration Experiment"
output:
  html_notebook: default
  pdf_document: default
---
[comment]: <> (Markdown Section. R code un {chunks})
Download and import dependencies.
```{r include=FALSE, echo=FALSE}
if(!require(psych)){install.packages('psych')} # for describe()
library(psych)

# Companion to Applied Regression CAR (who decides these horrible names?)
# for qqPlot,
# leveneTest for homogeneity of variance (for t-test) -> wrong, this is for independent samples t-test comparison
if(!require(car)){install.packages('car')} 
library(car)

# plot using a grid
if(!require(grid)){install.packages('grid')}
library(grid)

if(!require(gridExtra)){install.packages('gridExtra')}
library(gridExtra)

# for paired plots and other ready plots
if(!require(ggpubr)){install.packages('ggpubr')}
library(ggpubr)

if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)


# to find what's the data distribution
if(!require(fitdistrplus)){install.packages('fitdistrplus')}
library(fitdistrplus)
if(!require(logspline)){install.packages('logspline')}
library(logspline)

# for identify_outliers and others
if(!require(rstatix)){install.packages('rstatix')}
library(rstatix)

if(!require(afex)){install.packages('afex')}
library("afex")  

```

Set up working directory and read raw input files
```{r}
sprintf("current working directory = %s", getwd())
results_directory = "results"
questionnaire_raw_filename = paste(results_directory, "0_PostQuestionnaire.csv", sep="/")
questionnaire_raw <- read.csv(questionnaire_raw_filename, na.strings = c("-"))

# note:
# R renamed column names starting with a number to X<number>
```
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Part 1

Let's declare the name of the columns and whether they are a positive or negative question
```{r}
keyboard_columns = c(
  'X1_Complex_Keyboard',
  'X2_Easy_Keyboard',
  'X3_learn_quickly_Keyboard',
  'X4_Cumbersome_Keyboard',
  'X5_Confident_Keyboard',
  'X6_Learn_Lots_Keyboard',
  'X7_Fast_Keyboard',
  'X8_Accurate_Keyboard'
)


slider_columns = c(
  'X1_Complex_Slider',
  'X2_Easy_Slider',
  'X3_learn_quickly_Slider',
  'X4_Cumbersome_Slider',
  'X5_Confident_Slider',
  'X6_Learn_Lots_Slider',
  'X7_Fast_Slider',
  'X8_Accurate_Slider'
)

positivity = c(
    'X1_Complex' = F,
    'X2_Easy' = T,
    'X3_learn_quickly' = T,
    'X4_Cumbersome' = F,
    'X5_Confident' = T,
    'X6_Learn_Lots' = F,
    'X7_Fast' = T,
    'X8_Accurate' = T
)

get_base_name <- function(col_name)
{
  print(col_name)
  print(typeof(col_name))
  base = substr(col_name, 1, rfind(col_name, '_')-1)
  print(base)
  return(base)
}

get_base_name_cols <- function(col_names)
{
  return(lapply(col_names, get_base_name))
}
```

Let's create a dataframe with columns: id, question_1, ..., question_n, method
```{r}
ids = seq.int(nrow(questionnaire_raw))

keyboard_answers <- questionnaire_raw %>%
  select(ends_with("Keyboard"))

slider_answers <- questionnaire_raw %>%
  select(ends_with("Slider"))

keyboard_answers$method <- "Keyboard"
keyboard_answers$participant <- ids

slider_answers$method <- "Slider"
slider_answers$participant <- ids

keyboard_answers <- keyboard_answers %>%
  rename(
    X1_Complex = X1_Complex_Keyboard,
    X2_Easy = X2_Easy_Keyboard,
    X3_learn_quickly = X3_learn_quickly_Keyboard,
    X4_Cumbersome = X4_Cumbersome_Keyboard,
    X5_Confident = X5_Confident_Keyboard,
    X6_Learn_Lots = X6_Learn_Lots_Keyboard,
    X7_Fast = X7_Fast_Keyboard,
    X8_Accurate = X8_Accurate_Keyboard
)

slider_answers <- slider_answers %>%
  rename(
    X1_Complex = X1_Complex_Slider,
    X2_Easy = X2_Easy_Slider,
    X3_learn_quickly = X3_learn_quickly_Slider,
    X4_Cumbersome = X4_Cumbersome_Slider,
    X5_Confident = X5_Confident_Slider,
    X6_Learn_Lots = X6_Learn_Lots_Slider,
    X7_Fast = X7_Fast_Slider,
    X8_Accurate = X8_Accurate_Slider
)

sus_df <- bind_rows(keyboard_answers, slider_answers)

# let's invert the score of the negative questions
sus_df <- sus_df %>%
  mutate(
    X1_Complex = 4 - X1_Complex,
    X4_Cumbersome = 4 - X4_Cumbersome,
    X6_Learn_Lots = 4 - X6_Learn_Lots
  )

# 5 positive questions and 3 negative
# max score 8 x 4 = 32 -> scale_factor = 3.125
#scale_factor = 3.125
nr_questions <- 8 # change here depending on how many questions we want to consider
max_score_val <- 4
scale_factor <- 100 / (nr_questions * max_score_val)

sus_df <- sus_df %>%
  mutate(score = rowSums(.[1:nr_questions]) * scale_factor)

```

Let's plot the distribution of the scores
```{r}
p1 <- ggplot(sus_df, aes(score)) + geom_histogram()
p1 <- ggplot(sus_df, aes(score)) + geom_histogram()
p1 <- ggplot(sus_df, aes(score)) + geom_histogram()

sus_keyboard <- sus_df %>%
  filter(method == "Keyboard")

sus_slider <- sus_df %>%
  filter(method == "Slider")

p1_global <- ggplot(sus_df, aes(score)) + geom_histogram()
p1_keyboard <- ggplot(sus_keyboard, aes(score)) + geom_histogram()
p1_slider <- ggplot(sus_slider, aes(score)) + geom_histogram()

grid.arrange(p1_global, p1_keyboard, p1_slider, nrow=1)
```
Distribution of the scores group by condition

```{r}
ggdensity(sus_df,
  x = "score", # variable of interest
  add = "mean",# add vertical line for mean
  rug = TRUE, # add "rugs" to display the density of the values along the axis
  color = "method", fill = "method",
  palette = c("#00AFBB", "#E7B800"))
```
Paired T-Test out of curiosity
```{r}
# for paired t-test, differences need to be normally distributed
difference_t_test = sus_keyboard$score - sus_slider$score
hist(difference_t_test)
shapiro_test(difference_t_test) #0.023 -> not normal
qq_data <- as.data.frame(difference_t_test)
#str(qq_data)
#p1<-ggplot(qq_data, aes(sample=difference_t_test)) + stat_qq() + stat_qq_line()
#p1

# qqPlot from car package draws also surrounding area
qqPlot(difference_t_test)
t.test(sus_keyboard$score, sus_slider$score, paired = TRUE, alternative = "two.sided") #p-value 0.1642
```



Violion plot for the score
```{r}
a1 <- aov_ez("participant", "score", sus_df,
             between = NULL,
             within = c("method"),
             anova_table = list(es = "pes"))

## Check the normality of the residuals
# in this case, the residuals are not normal -> let's do a non-parametric test
residuals <- a1$lm$residuals
shapiro.test(residuals)
qqPlot(residuals)

# boxplot to see outliers
p1 <- afex_plot(a1, x = "method", error = "within", 
                 mapping = c("linetype", "shape", "fill"),
                 data_geom = ggplot2::geom_boxplot, 
                 data_arg = list(width = 0.5))

# violin plot to see distribution
p2 <- afex_plot(a1, x = "method", error = "within", 
                mapping = c("linetype", "shape", "fill"),
                data_geom = ggplot2::geom_violin, 
                data_arg = list(width = 0.5))

grid.arrange(p1, p2, nrow=1)

```
Non-parametric test for the SUS score
```{r}
#sus_keyboard$score
#sus_slider$score
# the scores for each condition are the same in 2 out of 16 participants.
difference <- sus_keyboard$score - sus_slider$score
difference
wilcox.test(sus_keyboard$score, sus_slider$score, paired = TRUE, alternative = "two.sided")
```
Let's analyze the questions one by one
```{r}
#set up empty variable to store all simulated p-values
nr_questions <- 8
p <-numeric(nr_questions) 

for (question_id in 1: nr_questions)
{
  keyboard_answers <- sus_keyboard[question_id]
  slider_answers <- sus_slider[question_id]
  
  keyboard_answers <- as.numeric(unlist(keyboard_answers))
  slider_answers <- as.numeric(unlist(slider_answers))
  
  differences <- keyboard_answers - slider_answers
  print(differences)
  print(paste("non-parametric test for question", question_id))

  test_result <- wilcox.test(keyboard_answers, slider_answers, paired = TRUE, alternative = "two.sided")
  p[question_id] <- test_result$p.value
}
print(p)
#q1_keyboard = sus_keyboard$X1_Complex

```

In most of the questions, wilcoxon test told us there were identical scores and
the p-values are not significant.
Only exception was question 7 (how fast the method was), with p-value of 0.0059

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
PART 2
Analysis of In-Experiment Measured Data (dynamic range, elapsed time)

```{r include=FALSE, echo=FALSE}
input_files <- list.files(
  path = results_directory,
  pattern = "*CalibrationMainTableTrials.csv",
  full.names = TRUE)

first_file <- TRUE
for (input_file in input_files)
{
  #print(input_file)
  first_index <- str_locate(input_file, "/")[1]
  last_index <- str_locate(input_file, "_")[1]
  participant_id <- strtoi(str_sub(input_file, first_index+1, last_index-1))
  # add participant id and add block order info
  partial_df <- read_delim(input_file, delim=';', skip=1, show_col_types = FALSE) %>%
    add_column(participant = participant_id) %>%
    mutate(repetition = if_else(trial == 1 | trial == 2, 1, 2)) %>%
    mutate(first = if_else(trial == 1 | trial == 3, TRUE, FALSE))
  
  if (first_file)
  {
    measured_data <- partial_df
    first_file <- FALSE
  } else {
    measured_data <- bind_rows(measured_data, partial_df)
  }
}

measured_data <- measured_data %>%
  rename(
    firstContactEndTrialElapsed = `firstContact-endTrial-elapsedTime`,
    firstContactLastContactElapsed = `firstContact-lastContact-elapsedTime`,
    firstContactLastSensationElapsed = `firstContact-lastSensation-elapsedTime`,)
measured_data$condition <- factor(measured_data$condition)

rm(partial_df)
```

Let's describe the data
```{r}
str(measured_data)
```
```{r}
measured_data %>%
  select(sensation, discomfort, dynamicRange, firstContactEndTrialElapsed, firstContactLastContactElapsed, firstContactLastSensationElapsed) %>%
  describe()
#describe(measured_data)
```


let's make a histogram of the measured variables
```{r}
p1 <- ggplot(measured_data, aes(sensation)) + geom_histogram()
p2 <- ggplot(measured_data, aes(discomfort)) + geom_histogram()
p3 <- ggplot(measured_data, aes(dynamicRange)) + geom_histogram()
p4 <- ggplot(measured_data, aes(firstContactLastContactElapsed)) + geom_histogram()
p5 <- ggplot(measured_data, aes(firstContactLastSensationElapsed)) + geom_histogram()
p6 <- ggplot(measured_data, aes(firstContactEndTrialElapsed)) + geom_histogram()
#p2<-ggplot(simulatedData, aes(d)) +
#  geom_histogram(binwidth = 4)
#p3<-qplot(simulatedData$d,geom="boxplot")
#p4<-ggplot(simulatedData, aes(sample = d)) + stat_qq() + stat_qq_line()

#grid.arrange(p1, p2, p3, p4)
#grid.arrange(p1, p2, p3, p4, p5, p6, nrow=1)
grid.arrange(p1, p2, p3, p4, p5, p6, nrow=2)


#hist(measured_data$firstContactEndTrialElapsed)
#boxplot(measured_data$`firstContact-endTrial-elapsedTime` ~ measured_data$condition)
```
Let's try to find the outliers regarding the calibration elapsed time
```{r include=FALSE, echo=FALSE}
nr_participants = n_distinct(measured_data$participant)

for (id in 1: nr_participants)
{
  participant_data <- measured_data %>%
  filter(participant == id)
  #ggtitle(paste("participant", id))
  p1 <- ggplot(participant_data, aes(firstContactEndTrialElapsed)) + geom_boxplot() + coord_flip()
  p2 <- ggplot(participant_data, aes(x=trial, y=firstContactEndTrialElapsed)) + geom_point()
  grid.arrange(p1, p2, nrow=1, top=textGrob(paste("participant ", id)))
}


```
Outliers and Extreme points
```{r}
# 4 outliers, one of them extreme.
# this were obtained using all datapoints and not using a "within-participant" comparison.
# 1, 15, 9 outliers
# 2 extreme outlier
measured_data_outliers <- identify_outliers(measured_data, variable="firstContactEndTrialElapsed")

# add outlier info to the main table
measured_data$outlier <- is_outlier(measured_data$firstContactEndTrialElapsed)
measured_data$extreme <- is_extreme(measured_data$firstContactEndTrialElapsed)

# show ""outliers""
#measured_data$participant[which(measured_data$extreme)]

# same as subset(df, filter, vars to show)
subset(measured_data, extreme, c(participant, trial, condition))
```



Identify data distribution

```{r}
descdist(measured_data$firstContactEndTrialElapsed, discrete = FALSE)
```

Let's plot some of the distributions against the observation
```{r}
scaled_data <- (measured_data$firstContactEndTrialElapsed - min(measured_data$firstContactEndTrialElapsed) + 0.001) / (max(measured_data$firstContactEndTrialElapsed) - min(measured_data$firstContactEndTrialElapsed) + 0.002)


fit.beta <- fitdist(scaled_data, "beta")
p1 <- plot(fit.beta)

fit.gamma <- fitdist(measured_data$firstContactEndTrialElapsed, "gamma")
p2 <- plot(fit.gamma)

# r internal function is called lnorm and not lognormal (stats package)
fit.lognormal <- fitdist(measured_data$firstContactEndTrialElapsed, "lnorm")
p3 <- plot(fit.lognormal)

p1

p2

p3
```
Data follows some lognormal distribution
let's transform the data

```{r}
measured_data <- measured_data %>%
    #add_column(logFirstContactEndTrialElapsed = log10(.$firstContactEndTrialElapsed))
    mutate(logFirstContactEndTrialElapsed = log10(firstContactEndTrialElapsed))


p1 <- ggplot(measured_data, aes(logFirstContactEndTrialElapsed)) + geom_histogram()
plot(p1)

shapiro_test(measured_data$logFirstContactEndTrialElapsed) # 0.95 -> data is normal

fit.normal <- fitdist(measured_data$logFirstContactEndTrialElapsed, "norm")
p2 <- plot(fit.normal)

p2


```

For now, let's not discard any trial yet and let's average the metrics per condition per participant

```{r}
grouped_data <-  measured_data %>%
  group_by(participant, condition) %>%
  summarise_at(
    vars(firstContactEndTrialElapsed, logFirstContactEndTrialElapsed, dynamicRange),
    mean)

grouped_data_keyboard <- grouped_data %>%
  filter(condition == "Keyboard")

grouped_data_slider <- grouped_data %>%
  filter(condition == "Slider")

p1_global <- ggplot(grouped_data, aes(logFirstContactEndTrialElapsed)) + geom_histogram()
p1_keyboard <- ggplot(grouped_data_keyboard, aes(logFirstContactEndTrialElapsed)) + geom_histogram()
p1_slider <- ggplot(grouped_data_slider, aes(logFirstContactEndTrialElapsed)) + geom_histogram()

grid.arrange(p1_global, p1_keyboard, p1_slider, nrow=1)
```
Let's plot distributions all together for the elapsed time variable
```{r}
ggdensity(grouped_data,
  x = "logFirstContactEndTrialElapsed", # variable of interest
  add = "mean",# add vertical line for mean
  rug = TRUE, # add "rugs" to display the density of the values along the axis
  color = "condition", fill = "condition",
  palette = c("#00AFBB", "#E7B800"))
```
And for the dynamic range
```{r}
ggdensity(grouped_data,
  x = "dynamicRange", # variable of interest
  add = "mean",# add vertical line for mean
  rug = TRUE, # add "rugs" to display the density of the values along the axis
  color = "condition", fill = "condition",
  palette = c("#00AFBB", "#E7B800"))
```



```{r}
p1_keyboard <- ggplot(grouped_data_keyboard, aes(firstContactEndTrialElapsed)) + geom_histogram()
p1_slider <- ggplot(grouped_data_slider, aes(firstContactEndTrialElapsed)) + geom_histogram()
grid.arrange(p1_keyboard, p1_slider, nrow=1)
```


Let's perform a T-test between the 2 conditions
Paired T-Test expect the difference between the two observations to be normally distributed
```{r}
difference_t_test = grouped_data_keyboard$logFirstContactEndTrialElapsed - grouped_data_slider$logFirstContactEndTrialElapsed
hist(difference_t_test)
shapiro_test(difference_t_test) #0.6265 -> normal
qq_data <- as.data.frame(difference_t_test)
#str(qq_data)
#p1<-ggplot(qq_data, aes(sample=difference_t_test)) + stat_qq() + stat_qq_line()
#p1

# qqPlot from car package draws also surrounding area
qqPlot(difference_t_test)
```

```{r}
# manual calculation of t-statistics
m <- mean(difference_t_test)
s <- sd(difference_t_test) # sample standard deviation
t <- m / (s / sqrt(length(difference_t_test)))
```



```{r}
#within-subjects
# we got p-value 0.008
t.test(grouped_data_keyboard$logFirstContactEndTrialElapsed, grouped_data_slider$logFirstContactEndTrialElapsed, paired = TRUE, alternative = "two.sided")
```
Let's plot the distribution per condition
```{r}
#boxplot(grouped_data$logFirstContactEndTrialElapsed~grouped_data$condition)
ggpaired(data = grouped_data, x = "condition" , y = "logFirstContactEndTrialElapsed", id="participant", fill="condition")
#grid.arrange(p1, p2, nrow=1)
```
and also for the dynamic range
The observations look pretty much one-to-one, i.e. for a given participant, its dynamic range didn't change
based on the keyboard/slider condition
```{r}
ggpaired(data = grouped_data, x = "condition" , y = "dynamicRange", id="participant", fill="condition")
```



```{r}
# What's the difference using pairwise.t.test to just t.test?
# I think functions is used when we want to simulate multiple t-tests
# this function performs a pooled sd t-test
# after making EXPLICIT paired=TRUE in a "pairwise" t-test, we get the same result as t.test.
# by inspecting the output, we can assume this function is mostly used for running multiple t-test
# between pairs of variables (PAIRWISE is for the variables and not for 'repeated measures')
pairwise.t.test(
  grouped_data$logFirstContactEndTrialElapsed, # response vector
  grouped_data$condition,#grouping vector
  #p.adjust.method="bonferroni", # 0.094 (same as holm)
  p.adjust.method="none",
  paired=TRUE,
  pool.sd=FALSE # we dont' want to assume sd is same for both conditions
  )
```



Let's see if the non-parametric test can also detect the difference between the 2 conditions

```{r}
wilcox.test(grouped_data_keyboard$firstContactEndTrialElapsed, grouped_data_slider$firstContactEndTrialElapsed, paired = TRUE, alternative = "two.sided")
```

Non-parametric test for dynamic range
there is no significant difference
```{r}
wilcox.test(grouped_data_keyboard$dynamicRange, grouped_data_slider$dynamicRange, paired = TRUE, alternative = "two.sided")
```


By doing an ANOVA paired test, do we get the same result as the T-test?
```{r}

# this is just one-way anova. not the right test but just to see the results
# imaging we don't have paired observations.
# results: if the observations were paired, then one-way anova's p-value = 0.0926 -> not significant
anova_one_way <- aov(logFirstContactEndTrialElapsed~condition, data = grouped_data)
summary(anova_one_way)
```
1-Way ANOVA repeated measures
```{r}
#anova_one_way_repeated <- aov(logFirstContactEndTrialElapsed~condition + Error(participant/condition), data = #grouped_data)
#summary(anova_one_way_repeated)

a1 <- aov_ez("participant", "firstContactEndTrialElapsed", grouped_data,
             between = NULL,
             within = c("condition"),
             anova_table = list(es = "pes"))

t.test(grouped_data_keyboard$firstContactEndTrialElapsed, grouped_data_slider$firstContactEndTrialElapsed, paired = TRUE, alternative = "two.sided")

## Check the normality of the residuals
residuals <- a1$lm$residuals
shapiro.test(residuals)
qqPlot(residuals)

afex_plot(a1, x = "condition", error = "within", 
                mapping = c("linetype", "shape", "fill"),
                data_geom = ggplot2::geom_boxplot, 
                data_arg = list(width = 0.5)) 

## Anova table
a1$anova_table

```


ANOVA for the dynamic Range
```{r}
a1 <- aov_ez("participant", "dynamicRange", grouped_data,
             between = NULL,
             within = c("condition"),
             anova_table = list(es = "pes"))

## Check the normality of the residuals
residuals <- a1$lm$residuals
shapiro.test(residuals)
qqPlot(residuals)

# boxplot to see outliers
p1 <- afex_plot(a1, x = "condition", error = "within", 
                 mapping = c("linetype", "shape", "fill"),
                 data_geom = ggplot2::geom_boxplot, 
                 data_arg = list(width = 0.5))

# violin plot to see distribution
p2 <- afex_plot(a1, x = "condition", error = "within", 
                mapping = c("linetype", "shape", "fill"),
                data_geom = ggplot2::geom_violin, 
                data_arg = list(width = 0.5))

grid.arrange(p1, p2, nrow=1)

## Anova table
a1$anova_table
```

